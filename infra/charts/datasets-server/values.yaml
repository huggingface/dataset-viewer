mongodb:
  enabled: false
  useStatefulSet: true
  auth:
    enabled: false
  serviceAccount:
    create: false
  # Name of the mongo db database used to cache the datasets
  cacheDatabase: "datasets_server_cache"
  # Name of the mongo db database used to store the jobs queue
  queueDatabase: "datasets_server_queue"

storage:
  nfs: {}

secrets:
  hfToken: datasets-server-hf-token
  mongoUrl: false

monitoring:
  enabled: false

domain: "datasets-server.us.dev.moon.huggingface.tech"
uid: 1000
gid: 3000

# Datasets blocklist
datasetsBlocklist: ""

docker:
  tag: sha-7982145

reverseProxy:
  image:
    repository: docker.io
    name: nginx
    tag: "1.20"
    pullPolicy: IfNotPresent

  replicas: 1

  service:
    type: NodePort
    annotations: { }

  ingress:
    annotations: { }

  resources:
    requests:
      cpu: 1
    limits:
      cpu: 1
  nodeSelector: {}
  tolerations: []

  # Directory of assets (audio files and images that will be served for the web)
  assetsDirectory: "/assets"
  # Directory of the nginx cache
  cacheDirectory: "/nginx-cache"
  readinessPort: 80
  cacheInactive: 24h
  cacheMaxSize: 1g
  cacheZoneSize: 50m
  host: localhost
  nginxTemplateFile: "nginx-templates/default.conf.template"
  port: 80

api:
  image:
    repository: 707930574880.dkr.ecr.us-east-1.amazonaws.com
    name: hub-datasets-server-api
    pullPolicy: IfNotPresent

  replicas: 1
  
  service:
    type: NodePort
    annotations: { }

  ingress:
    annotations: { }
  
  resources:
    requests:
      cpu: 1
    limits: 
      cpu: 1
  nodeSelector: {}
  tolerations: []

  # Directory of assets (audio files and images that will be served for the web)
  assetsDirectory: "/assets"
  readinessPort: 80
  # Application hostname - it must not be set to localhost to work in Kube!
  appHostname: "0.0.0.0"
  # Number of uvicorn workers for running the application
  appNumWorkers: "2"
  # Application endpoint port
  appPort: 80
  # Log level
  logLevel: "INFO"
  # Number of seconds to set in the `max-age` header on data endpoints
  maxAgeLongSeconds: "120"
  # Number of seconds to set in the `max-age` header on technical endpoints
  maxAgeShortSeconds: "10"  


datasetsWorker:
  image:
    repository: 707930574880.dkr.ecr.us-east-1.amazonaws.com
    name: hub-datasets-server-worker
    pullPolicy: IfNotPresent

  replicas: 1
  
  resources:
    requests:
      cpu: 1
    limits: 
      cpu: 1
  nodeSelector: {}
  tolerations: []

  # Directory of assets (audio files and images that will be served for the web)
  assetsDirectory: "/assets"
  # Directory of the "datasets" library cache (both for modules and datasets)
  cacheDirectory: "/cache"
  # Git reference for the canonical datasets on https://github.com/huggingface/datasets
  datasetsRevision: "master"
  # User Access Token (see https://huggingface.co/settings/token, only the `read` role is required)
  hfToken: ""
  # Log level
  logLevel: "INFO"
  # Maximum number of jobs running at the same time for the same dataset
  maxJobsPerDataset: 1
  # Max CPU load (%) - if reached, sleeps until it comes back under the limit
  maxLoadPct: 0
  # Max memory (RAM + SWAP) (%) - if reached, sleeps until it comes back under the limit
  maxMemoryPct: 0
  # Max size (in bytes) of the dataset to fallback in normal mode if streaming fails
  maxSizeFallback: "100_000_000"
  # Min size of a cell in the /rows endpoint response in bytes
  minCellBytes: 100
  # Max size of the /rows endpoint response in bytes
  rowMaxBytes: "1_000_000"
  # Max number of rows in the /rows endpoint response
  rowsMaxNumber: 100
  # Min number of rows in the /rows endpoint response
  rowsMinNumber: 10
  # Number of seconds a worker will sleep before trying to process a new job
  workerSleepSeconds: 15

splitsWorker:
  image:
    repository: 707930574880.dkr.ecr.us-east-1.amazonaws.com
    name: hub-datasets-server-worker
    pullPolicy: IfNotPresent
  replicas: 1
  
  resources:
    requests:
      cpu: 1
    limits: 
      cpu: 1
  nodeSelector: {}
  tolerations: []

  # Directory of assets (audio files and images that will be served for the web)
  assetsDirectory: "/assets"
  # Directory of the "datasets" library cache (both for modules and datasets)
  cacheDirectory: "/cache"
  # Git reference for the canonical datasets on https://github.com/huggingface/datasets
  datasetsRevision: "master"
  # Log level
  logLevel: "INFO"
  # Maximum number of jobs running at the same time for the same dataset
  maxJobsPerDataset: 1
  # Max CPU load (%) - if reached, sleeps until it comes back under the limit
  maxLoadPct: 0
  # Max memory (RAM + SWAP) (%) - if reached, sleeps until it comes back under the limit
  maxMemoryPct: 0
  # Max size (in bytes) of the dataset to fallback in normal mode if streaming fails
  maxSizeFallback: "100_000_000"
  # Min size of a cell in the /rows endpoint response in bytes
  minCellBytes: 100
  # Max size of the /rows endpoint response in bytes
  rowMaxBytes: "1_000_000"
  # Max number of rows in the /rows endpoint response
  rowsMaxNumber: 100
  # Min number of rows in the /rows endpoint response
  rowsMinNumber: 10
  # Number of seconds a worker will sleep before trying to process a new job
  workerSleepSeconds: 15


admin:
  image:
    repository: 707930574880.dkr.ecr.us-east-1.amazonaws.com
    name: hub-datasets-server-admin
    pullPolicy: IfNotPresent

  replicas: 1

  resources:
    requests:
      cpu: 1
    limits:
      cpu: 1
  nodeSelector: {}
  tolerations: []

  # Directory of assets (audio files and images that will be served for the web)
  assetsDirectory: "/assets"
  # Log level
  logLevel: "INFO"
