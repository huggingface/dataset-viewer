# SPDX-License-Identifier: Apache-2.0
# Copyright 2022 The HuggingFace Authors.

# --- common parameters ---
global:
  huggingface:
    ingress:
      domain: us.dev.moon.huggingface.tech
      # ^ the domain contains "dev", not "staging". We don't change for now.
      subdomains:
        datasetsServer: datasets-server

images:
  pullPolicy: IfNotPresent
  pullSecrets: []
  reverseProxy:
    useGlobalRegistry: false
    registry: docker.io
    repository: nginx
    tag: "1.25.3"
  jobs:
    mongodbMigration:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-mongodb_migration
      tag: sha-fb3399a
    cacheMaintenance:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-cache_maintenance
      tag: sha-fb3399a
  services:
    admin:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-admin
      tag: sha-fb3399a
    api:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-api
      tag: sha-fb3399a
    rows:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-rows
      tag: sha-fb3399a
    search:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-search
      tag: sha-fb3399a
    sseApi:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-sse-api
      tag: sha-fb3399a
    worker:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-worker
      tag: sha-fb3399a

secrets:
  externalSecret:
    enabled: true
    secretName: "datasets-server-staging-secrets"
    secretStoreName: "datasets-server-ephemeral-secretstore"
    parameters:
      MONGO_URL: "hub-ephemeral-datasets-server-mongo-url"
      HF_TOKEN: "hub-ephemeral-datasets-server-hf-token"
      PARQUET_CONVERTER_HF_TOKEN: "hub-ephemeral-datasets-server-parquet-converter-hf-token"
      WEBHOOK_SECRET: "hub-ephemeral-datasets-server-webhook-secret"
      SPAWNING_TOKEN: "hub-ephemeral-datasets-server-spawning-token"
      API_HF_JWT_ADDITIONAL_PUBLIC_KEYS: "hub-ephemeral-datasets-server-jwt-additional-public-keys"
      AWS_ACCESS_KEY_ID: "hub-ephemeral-datasets-server-s3-access-key-id"
      AWS_SECRET_ACCESS_KEY: "hub-ephemeral-datasets-server-s3-secret-access-key"
      CLOUDFRONT_KEY_PAIR_ID: "hub-ephemeral-datasets-server-cloudfront-key-id"
      CLOUDFRONT_PRIVATE_KEY: "hub-ephemeral-datasets-server-cloudfront-key"
  mongoUrl:
    fromSecret: true
    secretName: "datasets-server-staging-secrets"
  appHfToken:
    fromSecret: true
    secretName: "datasets-server-staging-secrets"
  appParquetConverterHfToken:
    fromSecret: true
    secretName: "datasets-server-staging-secrets"
  hfWebhookSecret:
    fromSecret: false
    secretName: "datasets-server-staging-secrets"
  hfJwtAdditionalPublicKeys:
    fromSecret: true
    secretName: "datasets-server-staging-secrets"
  spawningToken:
    fromSecret: true
    secretName: "datasets-server-staging-secrets"
  s3:
    accessKeyId:
      fromSecret: true
      secretName: "datasets-server-staging-secrets"
    secretAccessKey:
      fromSecret: true
      secretName: "datasets-server-staging-secrets"
  cloudfront:
    keyPairId:
      fromSecret: true
      secretName: "datasets-server-staging-secrets"
    privateKey:
      fromSecret: true
      secretName: "datasets-server-staging-secrets"

persistence:
  duckDBIndex:
    existingClaim: "datasets-server-duckdb-pvc"
  parquetMetadata:
    existingClaim: "datasets-server-parquet-pvc"

monitoring:
  enabled: true

mongodb:
  enabled: false

common:
  # URL of the HuggingFace Hub
  hfEndpoint: "https://huggingface.co"

log:
  # Log level
  level: "DEBUG"

firstRows:
  maxBytes: "200_000"

parquetAndInfo:
  maxDatasetSizeBytes: "500_000_000"

assets:
  storageRoot: "hf-datasets-server-statics-staging/assets"
  storageProtocol: "s3"

cachedAssets:
  storageRoot: "hf-datasets-server-statics-staging/cached-assets"
  storageProtocol: "s3"

# --- jobs (pre-install/upgrade hooks) ---

mongodbMigration:
  resources:
    requests:
      cpu: 100m
    limits:
      cpu: 1

# --- jobs (post-install/upgrade hooks) ---

deleteDuckdbIndexes:
  log:
    level: "debug"
  resources:
    requests:
      cpu: 100m
    limits:
      cpu: 1

# --- cron jobs  ---
backfill:
  enabled: false

queueMetricsCollector:
  action: "collect-queue-metrics"
  schedule: "*/10 * * * *"
  # every ten minutes, then it will be changed to default
  resources:
    requests:
      cpu: 1
    limits:
      cpu: 1
      memory: "512Mi"

# --- reverse proxy ---

reverseProxy:
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: "64Mi"
    limits:
      cpu: 1
      memory: "256Mi"
  service:
    type: NodePort

ingress:
  tls:
    - hosts:
        - "datasets-server.us.dev.moon.huggingface.tech"
  annotations:
    # Link to Route53 - we could set any subdomain to us.dev.moon.huggingface.tech (common zone to the k8s cluster)
    alb.ingress.kubernetes.io/load-balancer-name: "hub-datasets-server-staging"
    alb.ingress.kubernetes.io/tags: "Env=staging,Project=datasets-server,Terraform=true"
    alb.ingress.kubernetes.io/healthcheck-path: "/healthcheck"
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80, "HTTPS": 443}]'
    alb.ingress.kubernetes.io/scheme: "internet-facing"
    alb.ingress.kubernetes.io/group.name: "datasets-server"
    kubernetes.io/ingress.class: "alb"
    alb.ingress.kubernetes.io/group.order: "100"

# --- services ---

admin:
  uvicornNumWorkers: "1"
  replicas: 1
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/group.order: "1"
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

api:
  uvicornNumWorkers: "1"
  replicas: 1
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/actions.openapi-redirect: '{"Type":"redirect","RedirectConfig":{"Host":"raw.githubusercontent.com","Path":"/huggingface/dataset-viewer/main/docs/source/openapi.json","Port":"443","Protocol":"HTTPS","Query":"#{query}","StatusCode":"HTTP_307"}}'
      alb.ingress.kubernetes.io/actions.metrics-unauthorized: '{"type":"fixed-response","fixedResponseConfig":{"contentType":"text/plain","statusCode":"401","messageBody":"401 Unauthorized"}}'
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

rows:
  uvicornNumWorkers: "1"
  replicas: 1
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/group.order: "2"
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

search:
  uvicornNumWorkers: "1"
  replicas: 1
  service:
    type: NodePort
  ingress:
    enabled: true
    annotations:
      alb.ingress.kubernetes.io/group.order: "3"
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

workers:
  - deployName: "all"
    prometheusMultiprocDirectory: "/tmp"
    uvicornHostname: "0.0.0.0"
    uvicornNumWorkers: "1"
    uvicornPort: 8080
    workerDifficultyMax: 100
    workerDifficultyMin: 0
    workerJobTypesBlocked: ""
    workerJobTypesOnly: ""
    replicas: 1
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 5
      targets:
        - targetQueueName: "worker_size_jobs_count"
          targetQueueLength: 2
          targetWorkerSize: "heavy"
        - targetQueueName: "worker_size_jobs_count"
          targetQueueLength: 2
          targetWorkerSize: "medium"
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
  - deployName: "light"
    prometheusMultiprocDirectory: "/tmp"
    uvicornHostname: "0.0.0.0"
    uvicornNumWorkers: "1"
    uvicornPort: 8080
    workerDifficultyMax: 40
    workerDifficultyMin: 0
    workerJobTypesBlocked: ""
    workerJobTypesOnly: ""
    replicas: 1
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 5
      targets:
        - targetQueueName: "worker_size_jobs_count"
          targetQueueLength: 2
          targetWorkerSize: "light"
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
