# SPDX-License-Identifier: Apache-2.0
# Copyright 2022 The HuggingFace Authors.

# --- common parameters ---
global:
  huggingface:
    imageRegistry: ""
    imagePullSecrets: []
    privateHub:
      enabled: false
    ingress:
      domain: us.dev.moon.huggingface.tech
      subdomains:
        datasetsServer: datasets-server

images:
  pullPolicy: IfNotPresent
  pullSecrets: []
  reverseProxy:
    useGlobalRegistry: false
    registry: docker.io
    repository: nginx
    tag: "1.20"
  jobs:
    mongodbMigration:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-mongodb_migration
      tag: sha-fb3399a
    cacheRefresh:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-cache_refresh
      tag: sha-fb3399a
  services:
    admin:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-admin
      tag: sha-fb3399a
    api:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-api
      tag: sha-fb3399a
    worker:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-worker
      tag: sha-fb3399a

secrets:
  mongoUrl:
    fromSecret: false
    secretName: "mongo-url"
    value: mongo://
  appHfToken:
    fromSecret: true
    secretName: "datasets-server-hf-token"
  userHfToken:
    fromSecret: true
    secretName: "hf-token-francky"
  hfWebhookSecret:
    fromSecret: false
    secretName: "webhook-secret"
    value: ""

persistence:
  existingClaim: "nfs-datasets-server-pvc"

monitoring:
  enabled: false

mongodb:
  enabled: true

common:
  # URL of the HuggingFace Hub
  hfEndpoint: "https://huggingface.co"
  # Log level
  logLevel: "DEBUG"

parquetAndDatasetInfo:
  maxDatasetSize: "500_000_000"

# --- jobs (pre-install/upgrade hooks) ---

mongodbMigration:
  resources:
    requests:
      cpu: 100m
    limits:
      cpu: 1

# --- storage admin (to manually inspect the storage, in /data) ---

storageAdmin:
  replicas: 1
  resources:
    requests:
      cpu: 50m
      memory: "64Mi"
    limits:
      cpu: 1
      memory: "256Mi"

# --- reverse proxy ---

reverseProxy:
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: "64Mi"
    limits:
      cpu: 1
      memory: "256Mi"
  service:
    type: NodePort
  tolerations:
    - key: CriticalAddonsOnly
      operator: Equal

ingress:
  tls:
    - hosts:
      - "datasets-server.us.dev.moon.huggingface.tech"
  annotations:
    # Link to Route53 - we could set any subdomain to us.dev.moon.huggingface.tech (common zone to the k8s cluster)
    external-dns.alpha.kubernetes.io/hostname: "datasets-server.us.dev.moon.huggingface.tech"
    alb.ingress.kubernetes.io/load-balancer-name: "hub-datasets-server-dev"
    alb.ingress.kubernetes.io/tags: "Env=dev,Project=datasets-server,Terraform=true"
    alb.ingress.kubernetes.io/healthcheck-path: "/healthcheck"
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80, "HTTPS": 443}]'
    alb.ingress.kubernetes.io/scheme: "internet-facing"
    alb.ingress.kubernetes.io/group.name: "datasets-server"
    kubernetes.io/ingress.class: "alb"

# --- services ---

admin:
  uvicornNumWorkers: "1"

  replicas: 1
  service:
    type: NodePort
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

api:
  uvicornNumWorkers: "1"

  replicas: 1
  service:
    type: NodePort
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

workers:
  -
    deployName: "all"
    maxJobsPerNamespace: 1
    workerOnlyJobTypes: ""
    nodeSelector: {}
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
    tolerations: []
  -
    deployName: "light"
    maxJobsPerNamespace: 1
    workerOnlyJobTypes: "config-parquet,dataset-parquet,/dataset-info,/split-names-from-dataset-info,config-size,dataset-size,dataset-split-names-from-streaming,dataset-split-names-from-dataset-info"
    nodeSelector: {}
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
    tolerations: []
