# SPDX-License-Identifier: Apache-2.0
# Copyright 2022 The HuggingFace Authors.

# --- common parameters ---
global:
  huggingface:
    imageRegistry: ""
    imagePullSecrets: []
    privateHub:
      enabled: false
    ingress:
      domain: us.dev.moon.huggingface.tech
      subdomains:
        datasetsServer: datasets-server

images:
  pullPolicy: IfNotPresent
  pullSecrets: []
  reverseProxy:
    useGlobalRegistry: false
    registry: docker.io
    repository: nginx
    tag: "1.20"
  jobs:
    mongodbMigration:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-mongodb_migration
      tag: sha-fb3399a
    cacheMaintenance:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-jobs-cache_maintenance
      tag: sha-fb3399a
  services:
    admin:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-admin
      tag: sha-fb3399a
    api:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-api
      tag: sha-fb3399a
    worker:
      registry: huggingface
      useGlobalRegistry: false
      repository: datasets-server-services-worker
      tag: sha-fb3399a

secrets:
  mongoUrl:
    fromSecret: false
    secretName: "mongo-url"
    value: mongo://
  appHfToken:
    fromSecret: true
    secretName: "datasets-server-hf-token"
  userHfToken:
    fromSecret: true
    secretName: "hf-token-francky"
  hfWebhookSecret:
    fromSecret: false
    secretName: "webhook-secret"
    value: ""
  spawningToken:
    fromSecret: true
    secretName: "spawning-token"

persistence:
  existingClaim: "nfs-datasets-server-pvc"

monitoring:
  enabled: false

mongodb:
  enabled: true

common:
  # URL of the HuggingFace Hub
  hfEndpoint: "https://huggingface.co"

log:
  # Log level
  level: "DEBUG"

parquetAndInfo:
  maxDatasetSize: "500_000_000"

# --- jobs (pre-install/upgrade hooks) ---

mongodbMigration:
  resources:
    requests:
      cpu: 100m
    limits:
      cpu: 1

# --- jobs (post-upgrade hooks) ---

cacheMaintenance:
  action: "skip"
  # ^ allowed values are {skip,backfill,upgrade}
  resources:
    requests:
      cpu: 100m
    limits:
      cpu: 1

# --- cron jobs  ---
backfill:
  enabled: false

metricsCollector:
  action: "collect-metrics"
  schedule: "*/5 * * * *"
  # every five minutes
  nodeSelector: {}
  resources:
    requests:
      cpu: 0
    limits:
      cpu: 0
  tolerations: []

# --- storage admin (to manually inspect the storage, in /data) ---

storageAdmin:
  replicas: 1
  resources:
    requests:
      cpu: 50m
      memory: "64Mi"
    limits:
      cpu: 1
      memory: "256Mi"

# --- reverse proxy ---

reverseProxy:
  replicas: 1
  resources:
    requests:
      cpu: 100m
      memory: "64Mi"
    limits:
      cpu: 1
      memory: "256Mi"
  service:
    type: NodePort
  tolerations:
    - key: CriticalAddonsOnly
      operator: Equal

ingress:
  tls:
    - hosts:
      - "datasets-server.us.dev.moon.huggingface.tech"
  annotations:
    # Link to Route53 - we could set any subdomain to us.dev.moon.huggingface.tech (common zone to the k8s cluster)
    external-dns.alpha.kubernetes.io/hostname: "datasets-server.us.dev.moon.huggingface.tech"
    alb.ingress.kubernetes.io/load-balancer-name: "hub-datasets-server-dev"
    alb.ingress.kubernetes.io/tags: "Env=dev,Project=datasets-server,Terraform=true"
    alb.ingress.kubernetes.io/healthcheck-path: "/healthcheck"
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80, "HTTPS": 443}]'
    alb.ingress.kubernetes.io/scheme: "internet-facing"
    alb.ingress.kubernetes.io/group.name: "datasets-server"
    kubernetes.io/ingress.class: "alb"

# --- services ---

admin:
  uvicornNumWorkers: "1"

  replicas: 1
  service:
    type: NodePort
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

api:
  uvicornNumWorkers: "1"

  replicas: 1
  service:
    type: NodePort
  resources:
    requests:
      cpu: 100m
      memory: "512Mi"
    limits:
      cpu: 1
      memory: "4Gi"

workers:
  -
    deployName: "all"
    maxJobsPerNamespace: 1
    workerJobTypesBlocked: ""
    workerJobTypesOnly: ""
    nodeSelector: {}
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
    tolerations: []
  -
    deployName: "light"
    maxJobsPerNamespace: 1
    workerJobTypesBlocked: "dataset-config-names,config-split-names-from-streaming,config-parquet-and-info,split-first-rows-from-parquet,split-first-rows-from-streaming,split-opt-in-out-urls-scan"
    workerJobTypesOnly: ""
    nodeSelector: {}
    replicas: 1
    resources:
      requests:
        cpu: 100m
        memory: "512Mi"
      limits:
        cpu: 1
        memory: "4Gi"
    tolerations: []
