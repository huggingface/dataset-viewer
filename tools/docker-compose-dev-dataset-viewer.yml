x-common-env: &common-env
  # common
  COMMON_BLOCKED_DATASETS: ${COMMON_BLOCKED_DATASETS-}
  COMMON_HF_ENDPOINT: ${COMMON_HF_ENDPOINT-https://hub-ci.huggingface.co}
  COMMON_HF_TOKEN: ${COMMON_HF_TOKEN-hf_app_datasets-server_token}
  # log
  LOG_LEVEL: ${LOG_LEVEL-INFO}
  # huggingface_hub
  HF_ENDPOINT: ${COMMON_HF_ENDPOINT-https://hub-ci.huggingface.co} # see https://github.com/huggingface/datasets/pull/5196#issuecomment-1322191411
  # cache
  CACHE_MONGO_URL: ${CACHE_MONGO_URL-mongodb://${DEV_MONGO_HOST-host.docker.internal}:${MONGO_PORT-27017}}
  CACHE_MONGO_DATABASE: ${CACHE_MONGO_DATABASE-dataset_viewer_cache}
  # queue
  QUEUE_MONGO_URL: ${QUEUE_MONGO_URL-mongodb://${DEV_MONGO_HOST-host.docker.internal}:${MONGO_PORT-27017}}
  QUEUE_MONGO_DATABASE: ${QUEUE_MONGO_DATABASE-dataset_viewer_queue}
  # assets
  ASSETS_BASE_URL: ${ASSETS_BASE_URL} # <- must be set, no default value. If local, set to work with the reverse-proxy, like http://localhost:${PORT_REVERSE_PROXY-8000}/assets
  ASSETS_STORAGE_ROOT: ${ASSETS_STORAGE_ROOT-/storage/assets}
  ASSETS_STORAGE_PROTOCOL: ${ASSETS_STORAGE_PROTOCOL-file}
  # cached assets
  CACHED_ASSETS_BASE_URL: ${CACHED_ASSETS_BASE_URL} # <- must be set, no default value. If local, set to work with the reverse-proxy, like http://localhost:${PORT_REVERSE_PROXY-8000}/cached-assets
  CACHED_ASSETS_STORAGE_ROOT: ${CACHED_ASSETS_STORAGE_ROOT-/storage/cached-assets}
  CACHED_ASSETS_STORAGE_PROTOCOL: ${CACHED_ASSETS_STORAGE_PROTOCOL-file}
  # S3
  S3_ACCESS_KEY_ID: ${S3_ACCESS_KEY_ID-}
  S3_SECRET_ACCESS_KEY: ${S3_SECRET_ACCESS_KEY-}
  S3_REGION_NAME: ${S3_REGION_NAME-us-east-1}
  # cloudfront (for signed URLs)
  CLOUDFRONT_EXPIRATION_SECONDS: ${CLOUDFRONT_EXPIRATION_SECONDS-3600}
  CLOUDFRONT_KEY_PAIR_ID: ${CLOUDFRONT_KEY_PAIR_ID-}
  CLOUDFRONT_PRIVATE_KEY: ${CLOUDFRONT_PRIVATE_KEY-}
  # prometheus
  PROMETHEUS_MULTIPROC_DIR: ${PROMETHEUS_MULTIPROC_DIR-}

x-service-env: &service-env
  <<: *common-env
  NUMBA_CACHE_DIR: ${NUMBA_CACHE_DIR-/numba-cache}
  # service
  API_HF_AUTH_PATH: ${API_HF_AUTH_PATH-/api/datasets/%s/auth-check}
  API_HF_JWT_PUBLIC_KEY_URL: ${API_HF_JWT_PUBLIC_KEY_URL}
  API_HF_JWT_ADDITIONAL_PUBLIC_KEYS: ${API_HF_JWT_ADDITIONAL_PUBLIC_KEYS}
  API_HF_JWT_ALGORITHM: ${API_HF_JWT_ALGORITHM-EdDSA}
  API_HF_TIMEOUT_SECONDS: ${API_HF_TIMEOUT_SECONDS-10.0}
  API_MAX_AGE_LONG: ${API_MAX_AGE_LONG-120}
  API_MAX_AGE_SHORT: ${API_MAX_AGE_SHORT-10}

services:
  reverse-proxy:
    image: docker.io/nginx:1.25.3
    volumes:
      - ../tools/nginx-templates/:/etc/nginx/templates:ro
      - storage:${STORAGE_DIRECTORY-/storage}:ro
    ports:
      - "${PORT_REVERSE_PROXY-8000}:80"
    environment:
      ASSETS_STORAGE_ROOT: ${REVERSE_PROXY_ASSETS_STORAGE_ROOT-false} # <- if not set, returns 404 on /assets
      CACHED_ASSETS_STORAGE_ROOT: ${REVERSE_PROXY_CACHED_ASSETS_STORAGE_ROOT-false} # <- if not set, returns 404 on /cached-assets
      OPENAPI_FILE: ${OPENAPI_FILE-docs/source/openapi.json}
      HOST: localhost
      PORT: 80
      URL_ADMIN: http://host.docker.internal:${ADMIN_UVICORN_PORT-8081}
      URL_API: http://host.docker.internal:${API_UVICORN_PORT-8080}
      URL_ROWS: http://host.docker.internal:${ROWS_UVICORN_PORT-8082}
      URL_SEARCH: http://host.docker.internal:${SEARCH_UVICORN_PORT-8083}
      URL_SSE_API: http://host.docker.internal:${SSE_API_UVICORN_PORT-8085}
      URL_WEBHOOK: http://host.docker.internal:${WEBHOOK_UVICORN_PORT-8087}
    depends_on:
      admin:
        condition: service_started
      api:
        condition: service_started
      rows:
        condition: service_started
      search:
        condition: service_started
  admin:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: admin
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}:rw
      - parquet-metadata:${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}:ro
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      # service
      ADMIN_HF_ORGANIZATION: ${ADMIN_HF_ORGANIZATION-DVAdminsOrg}
      ADMIN_CACHE_REPORTS_NUM_RESULTS: ${ADMIN_CACHE_REPORTS_NUM_RESULTS-100}
      ADMIN_CACHE_REPORTS_WITH_CONTENT_NUM_RESULTS: ${ADMIN_CACHE_REPORTS_WITH_CONTENT_NUM_RESULTS-100}
      ADMIN_HF_TIMEOUT_SECONDS: ${ADMIN_HF_TIMEOUT_SECONDS-10.0}
      ADMIN_HF_WHOAMI_PATH: ${ADMIN_HF_WHOAMI_PATH-/api/whoami-v2}
      ADMIN_MAX_AGE: ${ADMIN_MAX_AGE-10}
      # uvicorn
      ADMIN_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      ADMIN_UVICORN_NUM_WORKERS: ${ADMIN_UVICORN_NUM_WORKERS-2}
      ADMIN_UVICORN_PORT: ${ADMIN_UVICORN_PORT-8081}
      PARQUET_METADATA_STORAGE_DIRECTORY: ${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: always
    ports:
      - ${ADMIN_UVICORN_PORT-8081}:${ADMIN_UVICORN_PORT-8081}
  api:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: api
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}:rw
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      # uvicorn
      API_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      API_UVICORN_NUM_WORKERS: ${API_UVICORN_NUM_WORKERS-2}
      API_UVICORN_PORT: ${API_UVICORN_PORT-8080}
    ports:
      - ${API_UVICORN_PORT-8080}:${API_UVICORN_PORT-8080}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
  rows:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: rows
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}
      - parquet-metadata:${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      PARQUET_METADATA_STORAGE_DIRECTORY: ${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}
      ROWS_INDEX_MAX_ARROW_DATA_IN_MEMORY: ${ROWS_INDEX_MAX_ARROW_DATA_IN_MEMORY-300_000_000}
      # uvicorn
      API_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      API_UVICORN_NUM_WORKERS: ${ROWS_UVICORN_NUM_WORKERS-2}
      API_UVICORN_PORT: ${ROWS_UVICORN_PORT-8082}
    ports:
      # for debug
      - ${ROWS_UVICORN_PORT-8082}:${ROWS_UVICORN_PORT-8082}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
  search:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: search
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}
      - parquet-metadata:${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}:rw
      - duckdb-index:${DUCKDB_INDEX_CACHE_DIRECTORY-/duckdb-index}:rw
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      DUCKDB_INDEX_CACHE_DIRECTORY: ${DUCKDB_INDEX_CACHE_DIRECTORY-/duckdb-index}
      DUCKDB_INDEX_EXTENSIONS_DIRECTORY: ${DUCKDB_INDEX_EXTENSIONS_DIRECTORY-/tmp/duckdb-extensions}
      PARQUET_METADATA_STORAGE_DIRECTORY: ${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}
      # uvicorn
      API_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      API_UVICORN_NUM_WORKERS: ${SEARCH_UVICORN_NUM_WORKERS-2}
      API_UVICORN_PORT: ${SEARCH_UVICORN_PORT-8083}
      HF_HUB_ENABLE_HF_TRANSFER: 1
    ports:
      # for debug
      - ${SEARCH_UVICORN_PORT-8083}:${SEARCH_UVICORN_PORT-8083}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
  sse-api:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: sse-api
    volumes:
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      # uvicorn
      API_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      API_UVICORN_NUM_WORKERS: ${SSE_API_UVICORN_NUM_WORKERS-2}
      API_UVICORN_PORT: ${SSE_API_UVICORN_PORT-8085}
    ports:
      # for debug
      - ${SSE_API_UVICORN_PORT-8085}:${SSE_API_UVICORN_PORT-8085}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
  worker:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: worker
    deploy:
      replicas: ${DEV_WORKER_REPLICAS-4}
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}:rw
      - parquet-metadata:${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}:rw
      - descriptive-statistics:${DESCRIPTIVE_STATISTICS_CACHE_DIRECTORY-/stats-cache}:rw
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *common-env
      COMMITTER_HF_TOKEN: ${COMMITTER_HF_TOKEN-hf_app_datasets-server-parquet-converter_token}
      CONFIG_NAMES_MAX_NUMBER: ${CONFIG_NAMES_MAX_NUMBER-3_000}
      DESCRIPTIVE_STATISTICS_CACHE_DIRECTORY: ${DESCRIPTIVE_STATISTICS_CACHE_DIRECTORY-/stats-cache}
      DESCRIPTIVE_STATISTICS_MAX_SPLIT_SIZE_BYTES: ${DESCRIPTIVE_STATISTICS_MAX_SPLIT_SIZE_BYTES-100_000_000}
      FIRST_ROWS_MAX_BYTES: ${FIRST_ROWS_MAX_BYTES-1_000_000}
      FIRST_ROWS_MIN_CELL_BYTES: ${FIRST_ROWS_MIN_CELL_BYTES-100}
      FIRST_ROWS_MIN_NUMBER: ${FIRST_ROWS_MIN_NUMBER-10}
      FIRST_ROWS_COLUMNS_MAX_NUMBER: ${FIRST_ROWS_COLUMNS_MAX_NUMBER-1_000}
      HF_HUB_ENABLE_HF_TRANSFER: 1
      OPT_IN_OUT_URLS_SCAN_COLUMNS_MAX_NUMBER: ${OPT_IN_OUT_URLS_SCAN_COLUMNS_MAX_NUMBER-10}
      OPT_IN_OUT_URLS_SCAN_MAX_CONCURRENT_REQUESTS_NUMBER: ${OPT_IN_OUT_URLS_SCAN_MAX_CONCURRENT_REQUESTS_NUMBER-100}
      OPT_IN_OUT_URLS_SCAN_MAX_REQUESTS_PER_SECOND: ${OPT_IN_OUT_URLS_SCAN_MAX_REQUESTS_PER_SECOND-50}
      OPT_IN_OUT_URLS_SCAN_ROWS_MAX_NUMBER: ${OPT_IN_OUT_URLS_SCAN_ROWS_MAX_NUMBER-100_000}
      OPT_IN_OUT_URLS_SCAN_SPAWNING_TOKEN: ${OPT_IN_OUT_URLS_SCAN_SPAWNING_TOKEN-}
      OPT_IN_OUT_URLS_SCAN_URLS_NUMBER_PER_BATCH: ${OPT_IN_OUT_URLS_SCAN_URLS_NUMBER_PER_BATCH-1000}
      OPT_IN_OUT_URLS_SCAN_SPAWNING_URL: ${OPT_IN_OUT_URLS_SCAN_SPAWNING_URL-https://opts-api.spawningaiapi.com/api/v2/query/urls}
      PARQUET_AND_INFO_COMMIT_MESSAGE: ${PARQUET_AND_INFO_COMMIT_MESSAGE-Update parquet files}
      PARQUET_AND_INFO_MAX_DATASET_SIZE_BYTES: ${PARQUET_AND_INFO_MAX_DATASET_SIZE_BYTES-200_000_000}
      PARQUET_AND_INFO_MAX_ROW_GROUP_BYTE_SIZE_FOR_COPY: ${PARQUET_AND_INFO_MAX_ROW_GROUP_BYTE_SIZE_FOR_COPY-100_000_000}
      PARQUET_AND_INFO_SOURCE_REVISION: ${PARQUET_AND_INFO_SOURCE_REVISION-main}
      PARQUET_AND_INFO_TARGET_REVISION: ${PARQUET_AND_INFO_TARGET_REVISION-refs/convert/parquet}
      PARQUET_AND_INFO_URL_TEMPLATE: ${PARQUET_AND_INFO_URL_TEMPLATE-/datasets/%s/resolve/%s/%s}
      PARQUET_METADATA_STORAGE_DIRECTORY: ${PARQUET_METADATA_STORAGE_DIRECTORY-/parquet_metadata}
      ROWS_INDEX_MAX_ARROW_DATA_IN_MEMORY: ${ROWS_INDEX_MAX_ARROW_DATA_IN_MEMORY-300_000_000}
      # uvicorn
      WORKER_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      WORKER_UVICORN_NUM_WORKERS: ${WORKER_UVICORN_NUM_WORKERS-2}
      WORKER_UVICORN_PORT: ${WORKER_UVICORN_PORT-8086}
      # datasets
      DATASETS_BASED_HF_DATASETS_CACHE: ${HF_DATASETS_CACHE-/datasets-cache}
      HF_MODULES_CACHE: ${HF_DATASETS_CACHE-/modules-cache}
      NUMBA_CACHE_DIR: ${NUMBA_CACHE_DIR-/numba-cache}
      # worker
      WORKER_CONTENT_MAX_BYTES: ${WORKER_CONTENT_MAX_BYTES-10_000_000}
      WORKER_KILL_LONG_JOB_INTERVAL_SECONDS: ${WORKER_KILL_LONG_JOB_INTERVAL_SECONDS-60}
      WORKER_KILL_ZOMBIES_INTERVAL_SECONDS: ${WORKER_KILL_ZOMBIES_INTERVAL_SECONDS-600}
      WORKER_MAX_JOB_DURATION_SECONDS: ${WORKER_MAX_JOB_DURATION_SECONDS-1200}
      WORKER_MAX_MISSING_HEARTBEATS: ${WORKER_MAX_MISSING_HEARTBEATS-5}
      WORKER_MAX_LOAD_PCT: ${WORKER_MAX_LOAD_PCT-70}
      WORKER_MAX_MEMORY_PCT: ${WORKER_MAX_MEMORY_PCT-80}
      WORKER_SLEEP_SECONDS: ${WORKER_SLEEP_SECONDS-15}
    # ports:
    #   - ${WORKER_UVICORN_PORT-8086}:${WORKER_UVICORN_PORT-8086}
    # ^ disabling, since having 4 replicas of the worker service with the same port causes issue:
    # Error response from daemon: driver failed programming external connectivity on endpoint
    # dev-dataset-viewer-worker-2 (3619ef10b728504a43005f0381d4bc98da5f3a398475f8e3b305b1f504f40012):
    # Bind for 0.0.0.0:8186 failed: port is already allocated
    depends_on:
      mongodb:
        condition: service_healthy
    restart: always
  webhook:
    build:
      context: ..
      dockerfile: ../Dockerfile
      target: webhook
    volumes:
      - storage:${STORAGE_DIRECTORY-/storage}:rw
      # volumes to local source directory for development
      - ..:/src
    environment:
      <<: *service-env
      COMMITTER_HF_TOKEN: ${COMMITTER_HF_TOKEN-hf_app_datasets-server-parquet-converter_token}
      # uvicorn
      API_UVICORN_HOSTNAME: 0.0.0.0 # required for docker compose
      API_UVICORN_NUM_WORKERS: ${WEBHOOK_UVICORN_NUM_WORKERS-2}
      API_UVICORN_PORT: ${WEBHOOK_UVICORN_PORT-8087}
    ports:
      - ${WEBHOOK_UVICORN_PORT-8087}:${WEBHOOK_UVICORN_PORT-8087}
    depends_on:
      mongodb:
        condition: service_healthy
    restart: unless-stopped
  mongodb:
    image: "mongo:6.0.9"
    ports:
      - ${MONGO_PORT:-27017}:${MONGO_PORT:-27017}
    command: mongod --port ${MONGO_PORT:-27017} --replSet ${MONGO_REPLICASET:-rs0} --bind_ip_all
    volumes:
      - mongo:/data/db:rw
    healthcheck:
      test: test $$(mongosh --port ${MONGO_PORT:-27017} --quiet --eval "try{rs.initiate({_id:'${MONGO_REPLICASET:-rs0}',version:1,members:[{_id:0,host:'mongodb:${MONGO_PORT:-27017}'}]})} catch(e) {rs.status().ok}") -eq 1
      interval: 2s
      timeout: 20s
      retries: 10
      start_period: 20s
      start_interval: 2s
volumes:
  storage:
  mongo:
  parquet-metadata:
  duckdb-index:
  descriptive-statistics:
