###########################
# make run/watch/test ... #
###########################

# Application hostname
# APP_HOSTNAME="localhost"

# Application port
# APP_PORT=8000

# Assets directory
# ASSETS_DIRECTORY=

# Enable private datasets
# DATASETS_ENABLE_PRIVATE=False

# Number of rows extracted from the dataset, if not specified otherwise
# EXTRACT_ROWS_LIMIT=100

# Git reference for the canonical datasets on https://github.com/huggingface/datasets
# DATASETS_REVISION="249b4a38390bf1543f5b6e2f3dc208b5689c1c13"

# Log level
# LOG_LEVEL = "INFO"

# Number of seconds to set in the `max-age` header on data endpoints
# MAX_AGE_LONG_SECONDS=21600

# Number of seconds to set in the `max-age` header on technical endpoints
# MAX_AGE_SHORT_SECONDS=120

# Name of the mongo db database used to cache the datasets
# MONGO_CACHE_DATABASE="datasets_preview_cache"

# Name of the mongo db database used to store the jobs queue
# MONGO_QUEUE_DATABASE="datasets_preview_queue"

# URL to connect to mongo db
# MONGO_URL="mongodb://localhost:27018"

# Number of uvicorn workers
# WEB_CONCURRENCY = 2

##########
# worker #
##########

# User Access Token (see https://huggingface.co/settings/token, only the `read` role is required)
# HF_TOKEN=

# Max CPU load (%) - if reached, sleeps until it comes back under the limit
# MAX_LOAD_PCT = 50

# Max memory (RAM + SWAP) (%) - if reached, sleeps until it comes back under the limit
# MAX_MEMORY_PCT = 60

# Max size (in bytes) of the dataset to fallback in normal mode if streaming fails
# MAX_SIZE_FALLBACK = 100_000_000

# Number of seconds a worker will sleep before trying to process a new job
# WORKER_SLEEP_SECONDS = 5

###########
# refresh #
###########

# Percentage of datasets to refresh
# REFRESH_PCT = 1
