# SPDX-License-Identifier: Apache-2.0
# Copyright 2022 The HuggingFace Authors.

import logging
from typing import Optional

from datasets import get_dataset_split_names
from datasets.builder import ManualDownloadError
from datasets.data_files import EmptyDatasetError as _EmptyDatasetError
from libcommon.constants import (
    PROCESSING_STEP_CONFIG_SPLIT_NAMES_FROM_INFO_VERSION,
    PROCESSING_STEP_CONFIG_SPLIT_NAMES_FROM_STREAMING_VERSION,
)
from libcommon.exceptions import (
    DatasetManualDownloadError,
    EmptyDatasetError,
    SplitNamesFromStreamingError,
)

from worker.dtos import CompleteJobResult, FullSplitItem, JobRunnerInfo, SplitsList
from worker.job_runners.config.config_job_runner import ConfigJobRunnerWithDatasetsCache
from worker.utils import disable_dataset_scripts_support


def compute_split_names_from_streaming_response(
    dataset: str,
    config: str,
    dataset_scripts_allow_list: list[str],
    hf_token: Optional[str] = None,
) -> SplitsList:
    """
    Get the response of config-split-names-from-streaming for one specific dataset and config on huggingface.co.
    Dataset can be private or gated if you pass an acceptable token.

    It is assumed that the dataset exists and can be accessed using the token, and that the config exists in
    the dataset.

    This function relies on the streaming mode if the splits are not directly defined in the dataset config. See
    https://github.dev/huggingface/datasets/blob/e183a269067575db8765ee979bd8523d14a1adae/src/datasets/inspect.py#L389-L390

    The config-split-names-from-streaming response generated by this function does not include stats about the split,
    like the size or number of samples. See dataset-info or dataset-size for that.

    Args:
        dataset (`str`):
            A namespace (user or an organization) and a repo name separated
            by a `/`.
        config (`str`):
            A configuration name.
        dataset_scripts_allow_list (`list[str]`):
            List of datasets for which we support dataset scripts.
            Unix shell-style wildcards also work in the dataset name for namespaced datasets,
            for example `some_namespace/*` to refer to all the datasets in the `some_namespace` namespace.
            The keyword `{{ALL_DATASETS_WITH_NO_NAMESPACE}}` refers to all the datasets without namespace.
        hf_token (`str`, *optional*):
            An authentication token (See https://huggingface.co/settings/token)
    Returns:
        `SplitsList`: An object with the list of split names for the dataset and config.
    Raises the following errors:
        - [`libcommon.exceptions.DatasetManualDownloadError`]:
          If the dataset requires manual download.
        - [`libcommon.exceptions.EmptyDatasetError`]
          The dataset is empty.
        - [`libcommon.exceptions.SplitsNamesError`]
          If the list of splits could not be obtained using the datasets library.
        - [`libcommon.exceptions.DatasetWithScriptNotSupportedError`]
            If the dataset has a dataset script and is not in the allow list.
    """
    logging.info(f"get split names for dataset={dataset}, config={config}")
    try:
        with disable_dataset_scripts_support(allow_list=dataset_scripts_allow_list):
            split_name_items: list[FullSplitItem] = [
                {"dataset": dataset, "config": config, "split": str(split)}
                for split in get_dataset_split_names(path=dataset, config_name=config, token=hf_token)
            ]
    except ManualDownloadError as err:
        raise DatasetManualDownloadError(f"{dataset=} requires manual download.", cause=err) from err
    except _EmptyDatasetError as err:
        raise EmptyDatasetError("The dataset is empty.", cause=err) from err
    except Exception as err:
        raise SplitNamesFromStreamingError(
            f"Cannot get the split names for the config '{config}' of the dataset.",
            cause=err,
        ) from err
    return SplitsList(splits=split_name_items)


class ConfigSplitNamesFromStreamingJobRunner(ConfigJobRunnerWithDatasetsCache):
    @staticmethod
    def get_job_type() -> str:
        return "config-split-names-from-streaming"

    @staticmethod
    def get_job_runner_version() -> int:
        return PROCESSING_STEP_CONFIG_SPLIT_NAMES_FROM_STREAMING_VERSION

    @staticmethod
    def get_parallel_job_runner() -> JobRunnerInfo:
        return JobRunnerInfo(
            job_runner_version=PROCESSING_STEP_CONFIG_SPLIT_NAMES_FROM_INFO_VERSION,
            job_type="config-split-names-from-info",
        )

    def compute(self) -> CompleteJobResult:
        return CompleteJobResult(
            compute_split_names_from_streaming_response(
                dataset=self.dataset,
                config=self.config,
                hf_token=self.app_config.common.hf_token,
                dataset_scripts_allow_list=self.app_config.common.dataset_scripts_allow_list,
            )
        )
